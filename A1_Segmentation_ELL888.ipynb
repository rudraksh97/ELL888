{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_Segmentation_ELL888.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO8sYt5oniAqcar5L3NiimB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlL3b0VbnvJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "from keras import backend\n",
        "from keras.models import *\n",
        "from keras.metrics import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.preprocessing.image import load_img\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mCYuLsE5UMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHmvBT4cE8PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resized(img_path):\n",
        "  img = cv.imread(img_path)\n",
        "  img = cv.resize(img,(256,256))\n",
        "  img = img/255.0\n",
        "  return img"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxMqpDuTDSgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ap = []\n",
        "lat = []\n",
        "ap_v = []\n",
        "ap_s = []\n",
        "ap_p = []\n",
        "lat_v = []\n",
        "lat_a = []\n",
        "lat_d = []\n",
        "lat_s = []\n",
        "lat_p = []\n",
        "\n",
        "textr = open(\"location_train.txt\").read()\n",
        "files = textr.split(\"\\n\")\n",
        "\n",
        "for file in files:\n",
        "  if(\"ap.\" in file.lower()):\n",
        "    ap.append(file)\n",
        "  elif(\"lat.\" in file.lower()):\n",
        "    lat.append(file)\n",
        "  elif(\"lat_a\" in file.lower()):\n",
        "    lat_a.append(file)\n",
        "  elif(\"lat_v\" in file.lower()):\n",
        "    lat_v.append(file)\n",
        "  elif(\"lat_p\" in file.lower()):\n",
        "    lat_p.append(file)\n",
        "  elif(\"lat_d\" in file.lower()):\n",
        "    lat_d.append(file)\n",
        "  elif(\"lat_s\" in file.lower()):\n",
        "    lat_s.append(file)\n",
        "  elif(\"ap_v\" in file.lower()):\n",
        "    ap_v.append(file)\n",
        "  elif(\"ap_s\" in file.lower()):\n",
        "    ap_s.append(file)\n",
        "  elif(\"ap_p\" in file.lower()):\n",
        "    ap_p.append(file)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToUaVQsDpbzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ap_seg = [ap_p,ap_s,ap_v] \n",
        "lat_seg = [lat_a,lat_d,lat_p,lat_s,lat_v]\n",
        "\n",
        "AP = []\n",
        "LAT = []\n",
        "\n",
        "for i in range(3):\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(ap,ap_seg[i], test_size = 0.2, random_state=42)\n",
        "  AP.append([X_train, X_valid, y_train, y_valid])\n",
        "\n",
        "for i in range(5):\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(lat,lat_seg[i], test_size = 0.2, random_state=42)\n",
        "  LAT.append([X_train, X_valid, y_train, y_valid])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0DiMe1Zx2fJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_generator(X,y, batch_size):\n",
        "  while True:\n",
        "    batch  = np.random.choice(len(X),size = batch_size)\n",
        "    batch_input  = []\n",
        "    batch_output = []\n",
        "    \n",
        "    for i in batch:\n",
        "      output = resized(y[i])\n",
        "      input = resized(X[i])\n",
        "      batch_input += [input]\n",
        "      batch_output += [output]\n",
        "      \n",
        "    batch_x = np.array(batch_input)\n",
        "    batch_y = np.array(batch_output)\n",
        "    \n",
        "    yield (batch_x, batch_y)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIjhp3MiGR9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(image,n_filters,size_kernel):\n",
        "    out = Conv2D(filters = n_filters, kernel_size = (size_kernel,size_kernel), padding = 'same',kernel_initializer = 'he_normal')(image)\n",
        "    out = BatchNormalization()(out)\n",
        "    out = Activation('relu')(out)\n",
        "    out = Conv2D(filters = n_filters, kernel_size = (size_kernel,size_kernel), padding = 'same',kernel_initializer = 'he_normal')(out)\n",
        "    out = BatchNormalization()(out)\n",
        "    out = Activation('relu')(out)\n",
        "    return out\n",
        "\n",
        "def up_sampling(n_filters,dropout,convh,convd):\n",
        "  up = Conv2DTranspose(n_filters, (3, 3), strides = (2, 2), padding = 'same')(convh)\n",
        "  up = concatenate([up, convd])\n",
        "  up = Dropout(rate=dropout)(up)\n",
        "  conv = conv_block(up,n_filters,3)\n",
        "  return conv\n",
        "\n",
        "def unet(image,n_filters,kernel_size,dropout):    \n",
        "  conv1 = conv_block(image,n_filters,kernel_size)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "  n_filters = n_filters*2\n",
        "  conv2 = conv_block(pool1,n_filters,kernel_size) \n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "  n_filters = n_filters*2\n",
        "  conv3 = conv_block(pool2,n_filters,kernel_size)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "  n_filters = n_filters*2\n",
        "  conv4 = conv_block(pool3,n_filters,kernel_size)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "  n_filters = n_filters*2\n",
        "  conv5 = conv_block(pool4,n_filters,kernel_size)\n",
        "  conv_seq = [conv4,conv3,conv2,conv1]\n",
        "  out = conv5\n",
        " \n",
        "  for convd in conv_seq:\n",
        "    n_filters = int(n_filters/2)\n",
        "    out = up_sampling(n_filters,dropout,convh=out,convd=convd)\n",
        "\n",
        "  output = Conv2D(3, (1, 1), activation='sigmoid')(out)\n",
        "  model = Model(inputs=[image], outputs=[output])\n",
        "  return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDjYp3W2J1Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input((256,256,3))\n",
        "filepath_ap=[\"ap_weights1.hdf5\",\"ap_weights2.hdf5\",\"ap_weights3.hdf5\"]\n",
        "filepath_lat=[\"lat_weights1.hdf5\",\"lat_weights2.hdf5\",\"lat_weights3.hdf5\",\"lat_weights4.hdf5\",\"lat_weights5.hdf5\"]\n",
        "\n",
        "model = unet(input_img, n_filters=16,kernel_size=3,dropout=0.1)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "checkpoint = ModelCheckpoint(filepath_ap[1], monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "results = model.fit_generator(image_generator(AP[1][0],AP[1][2],10),steps_per_epoch=56, epochs=20,validation_data=image_generator(AP[1][1],AP[1][3],10),validation_steps=6,callbacks = [checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7MDHr8FzV5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = unet(input_img, n_filters=16,kernel_size=3,dropout=0.1)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
        "checkpoint = ModelCheckpoint(filepath_lat[j], monitor='val_iou', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "results = model.fit_generator(image_generator(LAT[j][0],LAT[j][2],10),steps_per_epoch=50, epochs=20,validation_data=image_generator(LAT[j][1],LAT[j][3],10),validation_steps=12,callbacks = [callbacks_list])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}